---
title: 'Perception Test 2025 Report: Where Generalist Models Still Fall Short'
publishedAt: '2026-01-09'
summary: 'The consolidated evaluation of multimodal perception tasks is out. It highlights real gaps in generalist models—and what we need to fix next.'
---

The **Perception Test 2025** report is the kind of evaluation that shapes the next year. It’s a **consolidated** look at **multimodal perception**: one evaluation across many tasks and datasets, designed to show where **generalist models** still fail. The report (and related work, e.g. arxiv.org/abs/2601.06287) is the closest thing to a “state of the union” for perception—and it’s sobering in the right places.

I use these reports to set priorities: if generalist models are weak on temporal reasoning or fine-grained grounding, that’s where I expect the next wave of papers and products to focus. Here’s what the Perception Test 2025 report is about and why it matters.

## What the Report Covers

**Multimodal perception**—vision + language, vision + audio, and cross-modal reasoning. The test isn’t “can the model caption?” but “can it localize, reason, and answer in a way that’s grounded and consistent across modalities?”

**Gaps in generalist models**—where do SOTA models still drop the ball? Often it’s long-horizon video, fine-grained spatial reasoning, or tasks that need explicit chain-of-thought. The report names the gaps so the community can target them.

**Benchmarks and metrics**—unified protocols so different groups can compare. ICCV workshops and follow-up papers build on this so “better perception” is measurable.

## Why It Matters

One-off benchmarks can be gamed. A **consolidated** evaluation that spans tasks and modalities is harder to overfit and gives a clearer picture of “how far are we?” If you’re in research or product, the Perception Test 2025 report and the related arxiv/ICCV material are the right place to see where the field stands and where it’s heading.

---

*Part of the CV timeline. More in the blog—follow for the next one.*
